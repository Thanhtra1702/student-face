import os
import cv2
import shutil
import numpy as np
from deepface import DeepFace
from qdrant_client import QdrantClient, models
from qdrant_client.models import PointStruct
import sys
import datetime

sys.stdout.reconfigure(encoding='utf-8')

COLLECTED_DIR = "collected_faces"
PROCESSED_DIR = "collected_faces/processed"
DATABASE_DIR = "database"
DB_PATH = "./qdrant_db"
COLLECTION_NAME = "student_faces"

# --- AI ENHANCEMENT HELPERS (ƒê·ªìng b·ªô v·ªõi app.py v√† init_qdrant.py) ---
def preprocess_frame(frame):
    """C√¢n b·∫±ng s√°ng v√† kh·ª≠ nhi·ªÖu ƒë·ªÉ AI d·ªÖ ƒë·ªçc h∆°n"""
    try:
        denoised = cv2.GaussianBlur(frame, (3, 3), 0)
        lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        cl = clahe.apply(l)
        limg = cv2.merge((cl, a, b))
        final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
        return final
    except:
        return frame

def rotate_image(image, angle):
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(image, M, (w, h))
# -----------------------------------------------------------------------

def process_collected_images():
    if not os.path.exists(COLLECTED_DIR):
        print(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {COLLECTED_DIR}")
        return

    if not os.path.exists(PROCESSED_DIR):
        os.makedirs(PROCESSED_DIR)

    # L·∫•y danh s√°ch ·∫£nh (bao g·ªìm c·∫£ trong subfolders)
    image_files = []
    for root, dirs, files in os.walk(COLLECTED_DIR):
        # B·ªè qua th∆∞ m·ª•c 'processed'
        if 'processed' in root.replace('\\', '/').split('/'):
            continue
            
        for file in files:
            if file.lower().endswith(('.jpg', '.png')):
                image_files.append(os.path.join(root, file))
    
    if not image_files:
        print("Kh√¥ng c√≥ ·∫£nh n√†o c·∫ßn x·ª≠ l√Ω.")
        return

    print(f"üîç T√¨m th·∫•y {len(image_files)} ·∫£nh c·∫ßn x·ª≠ l√Ω...")
    
    # Init Qdrant Client m·ªôt l·∫ßn
    client = QdrantClient(path=DB_PATH)

    count_success = 0
    
    for file_path in image_files:
        filename = os.path.basename(file_path)
        parent_dir_name = os.path.basename(os.path.dirname(file_path))
        
        # LOGIC CHU·∫®N: Ch·ªâ nh·∫≠n ·∫£nh trong Folder con (collected_faces/MSSV/...)
        if parent_dir_name == "collected_faces" or parent_dir_name == "processed":
            print(f"‚ö†Ô∏è B·ªè qua ·∫£nh kh√¥ng n·∫±m trong th∆∞ m·ª•c MSSV: {filename}")
            continue
            
        mssv = parent_dir_name
        
        print(f"\nüì∏ ƒêang x·ª≠ l√Ω: {filename} (MSSV: {mssv})")
        
        # 1. ƒê·ªçc v√† Ti·ªÅn x·ª≠ l√Ω (ƒê·ªìng b·ªô v·ªõi app.py)
        img_raw = cv2.imread(file_path)
        if img_raw is None:
            print("‚ùå L·ªói ƒë·ªçc ·∫£nh.")
            continue
        
        img = preprocess_frame(img_raw)

        try:
            # ... (Ph·∫ßn Detection gi·ªØ nguy√™n) ...
            # Detect & Crop (S·ª≠ d·ª•ng logic th√¥ng minh: Di·ªán t√≠ch + V·ªã tr√≠ trung t√¢m)
            try:
                results = DeepFace.represent(
                    img_path=img,
                    model_name="ArcFace",
                    enforce_detection=True,
                    detector_backend="mediapipe",
                    align=True
                )
            except:
                 results = DeepFace.represent(
                    img_path=img,
                    model_name="ArcFace",
                    enforce_detection=True,
                    detector_backend="opencv",
                    align=True
                )

            if not results:
                print("‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t.")
                continue

            # Logic ch·ªçn khu√¥n m·∫∑t t·ªët nh·∫•t
            img_height, img_width = img.shape[:2]
            img_center_x = img_width / 2
            img_center_y = img_height / 2
            
            best_face = None
            best_score = -1
            
            for face_data in results:
                fa = face_data['facial_area']
                area = fa['w'] * fa['h']
                face_center_x = fa['x'] + fa['w'] / 2
                face_center_y = fa['y'] + fa['h'] / 2
                distance = ((face_center_x - img_center_x)**2 + (face_center_y - img_center_y)**2)**0.5
                max_distance = (img_width**2 + img_height**2)**0.5
                distance_score = 1 - (distance / max_distance)
                max_area = img_width * img_height
                area_score = area / max_area
                total_score = 0.7 * area_score + 0.3 * distance_score
                
                if total_score > best_score:
                    best_score = total_score
                    best_face = face_data
            
            # Crop & Save
            target_path = os.path.join(DATABASE_DIR, f"{mssv}.jpg")
            
            # T√≠nh to√°n v√πng crop c√≥ padding
            facial_area = best_face['facial_area']
            padding = 0.2
            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']
            x_pad, y_pad = int(w * padding), int(h * padding)
            x1 = max(0, x - x_pad)
            y1 = max(0, y - y_pad)
            x2 = min(img_width, x + w + x_pad)
            y2 = min(img_height, y + h + y_pad)
            
            face_crop = img[y1:y2, x1:x2]
            
            # --- LOGIC CH·ªåN ·∫¢NH T·ªêT NH·∫§T (SMART AVATAR SELECTION) ---
            should_save_image = True
            if os.path.exists(target_path):
                # N·∫øu ·∫£nh ƒë√£ t·ªìn t·∫°i, so s√°nh ch·∫•t l∆∞·ª£ng (D·ª±a tr√™n ƒë·ªô ph√¢n gi·∫£i)
                try:
                    old_img = cv2.imread(target_path)
                    if old_img is not None:
                        old_h, old_w = old_img.shape[:2]
                        new_h, new_w = face_crop.shape[:2]
                        
                        old_area = old_w * old_h
                        new_area = new_w * new_h
                        
                        # Ch·ªâ thay th·∫ø n·∫øu ·∫£nh m·ªõi L·ªöN H∆†N ·∫£nh c≈© (R√µ n√©t h∆°n)
                        if new_area <= old_area:
                            should_save_image = False
                            print(f"‚ÑπÔ∏è Gi·ªØ nguy√™n Avatar c≈© (M·ªõi: {new_w}x{new_h} <= C≈©: {old_w}x{old_h})")
                        else:
                            print(f"üÜô C·∫≠p nh·∫≠t Avatar ch·∫•t l∆∞·ª£ng cao h∆°n ({old_w}x{old_h} -> {new_w}x{new_h})")
                except:
                    pass # L·ªói ƒë·ªçc ·∫£nh c≈© -> C·ª© ghi ƒë√® cho ch·∫Øc

            if should_save_image:
                cv2.imwrite(target_path, face_crop)
                print(f"‚úÖ ƒê√£ l∆∞u Avatar m·ªõi: {target_path}")
            # --------------------------------------------------------

            # 2. Update Qdrant (C∆° ch·∫ø Multi-Vector + Augmentation: T·∫°o x8 variants)
            # T·∫°o c√°c bi·∫øn th·ªÉ (Augmentation - Buff m·∫°nh ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c)
            # D√πng cv2.convertScaleAbs cho Brightness/Contrast
            variants = [
                ("orig", face_crop),
                ("flip", cv2.flip(face_crop, 1)),
                ("rot_p5", rotate_image(face_crop, 5)),
                ("rot_m5", rotate_image(face_crop, -5)),
                ("bright", cv2.convertScaleAbs(face_crop, alpha=1.2, beta=30)), # S√°ng h∆°n
                ("dark", cv2.convertScaleAbs(face_crop, alpha=0.8, beta=-20)),   # T·ªëi h∆°n
                ("contrast", cv2.convertScaleAbs(face_crop, alpha=1.5, beta=0)), # T∆∞∆°ng ph·∫£n cao
                ("blur", cv2.GaussianBlur(face_crop, (3, 3), 0))                # Nh√≤e nh·∫π
            ]
            
            import uuid
            for var_name, var_img in variants:
                try:
                    # Chuy·ªÉn sang RGB tr∆∞·ªõc khi x·ª≠ l√Ω
                    rgb_var = cv2.cvtColor(var_img, cv2.COLOR_BGR2RGB)
                    
                    results_var = DeepFace.represent(
                        img_path=rgb_var,
                        model_name="ArcFace",
                        enforce_detection=False,
                        detector_backend="mediapipe",
                        align=True
                    )
                    if results_var:
                        embedding = results_var[0]['embedding']
                        point_id = str(uuid.uuid4())
                        client.upsert(
                            collection_name=COLLECTION_NAME,
                            points=[
                                PointStruct(
                                    id=point_id,
                                    vector=embedding,
                                    payload={"student_id": mssv, "variant": var_name}
                                )
                            ]
                        )
                except:
                    pass
            
            print(f"‚úÖ ƒê√£ th√™m 4 variants v√†o Qdrant cho {mssv}.")

            # 3. L∆∞u tr·ªØ: Di chuy·ªÉn ·∫£nh v√†o th∆∞ m·ª•c processed thay v√¨ x√≥a (ƒë·ªÉ ƒë·ªëi so√°t)
            try:
                # T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c MSSV b√™n trong processed
                dest_dir = os.path.join(PROCESSED_DIR, mssv)
                if not os.path.exists(dest_dir):
                    os.makedirs(dest_dir)
                
                # Di chuy·ªÉn file (th√™m timestamp ƒë·ªÉ tr√°nh tr√πng t√™n n·∫øu 1 MSSV c√≥ nhi·ªÅu ·∫£nh)
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                dest_path = os.path.join(dest_dir, f"{timestamp}_{filename}")
                
                shutil.move(file_path, dest_path)
                print(f"üì¶ ƒê√£ l∆∞u tr·ªØ ·∫£nh g·ªëc v√†o: {dest_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u tr·ªØ file {filename}: {e}")
            
            # X√≥a th∆∞ m·ª•c r·ªóng trong collected_faces n·∫øu c·∫ßn
            parent_dir = os.path.dirname(file_path)
            if not os.listdir(parent_dir) and parent_dir != COLLECTED_DIR:
                try:
                    os.rmdir(parent_dir)
                except: pass
                
            count_success += 1

        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω {filename}: {e}")

    print("\n" + "="*50)
    print(f"üéâ Ho√†n t·∫•t! ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {count_success}/{len(image_files)} ·∫£nh.")

if __name__ == "__main__":
    process_collected_images()
