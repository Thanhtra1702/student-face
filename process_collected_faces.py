import os
import cv2
import shutil
import numpy as np
from deepface import DeepFace
from qdrant_client import QdrantClient, models
from qdrant_client.models import PointStruct
import sys
import datetime

sys.stdout.reconfigure(encoding='utf-8')

COLLECTED_DIR = "collected_faces"
PROCESSED_DIR = "collected_faces/processed"
DATABASE_DIR = "database"
DB_PATH = "./qdrant_db"
COLLECTION_NAME = "student_faces"

def process_collected_images():
    if not os.path.exists(COLLECTED_DIR):
        print(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {COLLECTED_DIR}")
        return

    if not os.path.exists(PROCESSED_DIR):
        os.makedirs(PROCESSED_DIR)

    # L·∫•y danh s√°ch ·∫£nh (bao g·ªìm c·∫£ trong subfolders)
    image_files = []
    for root, dirs, files in os.walk(COLLECTED_DIR):
        # B·ªè qua th∆∞ m·ª•c 'processed'
        if 'processed' in root.replace('\\', '/').split('/'):
            continue
            
        for file in files:
            if file.lower().endswith(('.jpg', '.png')):
                image_files.append(os.path.join(root, file))
    
    if not image_files:
        print("Kh√¥ng c√≥ ·∫£nh n√†o c·∫ßn x·ª≠ l√Ω.")
        return

    print(f"üîç T√¨m th·∫•y {len(image_files)} ·∫£nh c·∫ßn x·ª≠ l√Ω...")
    
    # Init Qdrant Client m·ªôt l·∫ßn
    client = QdrantClient(path=DB_PATH)

    count_success = 0
    
    for file_path in image_files:
        filename = os.path.basename(file_path)
        
        # Parse MSSV t·ª´ t√™n file (Format: MSSV_Timestamp.jpg)
        try:
            mssv = filename.split('_')[0]
        except:
            print(f"‚ö†Ô∏è T√™n file kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng: {filename}")
            continue

        print(f"\nüì∏ ƒêang x·ª≠ l√Ω: {filename} (MSSV: {mssv})")
        
        # 1. ƒê·ªçc v√† Crop ·∫£nh
        img = cv2.imread(file_path)
        if img is None:
            print("‚ùå L·ªói ƒë·ªçc ·∫£nh.")
            continue

        try:
            # ... (Ph·∫ßn Detection gi·ªØ nguy√™n) ...
            # Detect & Crop (S·ª≠ d·ª•ng logic th√¥ng minh: Di·ªán t√≠ch + V·ªã tr√≠ trung t√¢m)
            try:
                results = DeepFace.represent(
                    img_path=img,
                    model_name="ArcFace",
                    enforce_detection=True,
                    detector_backend="mediapipe",
                    align=True
                )
            except:
                 results = DeepFace.represent(
                    img_path=img,
                    model_name="ArcFace",
                    enforce_detection=True,
                    detector_backend="opencv",
                    align=True
                )

            if not results:
                print("‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t.")
                continue

            # Logic ch·ªçn khu√¥n m·∫∑t t·ªët nh·∫•t
            img_height, img_width = img.shape[:2]
            img_center_x = img_width / 2
            img_center_y = img_height / 2
            
            best_face = None
            best_score = -1
            
            for face_data in results:
                fa = face_data['facial_area']
                area = fa['w'] * fa['h']
                face_center_x = fa['x'] + fa['w'] / 2
                face_center_y = fa['y'] + fa['h'] / 2
                distance = ((face_center_x - img_center_x)**2 + (face_center_y - img_center_y)**2)**0.5
                max_distance = (img_width**2 + img_height**2)**0.5
                distance_score = 1 - (distance / max_distance)
                max_area = img_width * img_height
                area_score = area / max_area
                total_score = 0.7 * area_score + 0.3 * distance_score
                
                if total_score > best_score:
                    best_score = total_score
                    best_face = face_data
            
            # Crop & Save
            target_path = os.path.join(DATABASE_DIR, f"{mssv}.jpg")
            
            # T√≠nh to√°n v√πng crop c√≥ padding
            facial_area = best_face['facial_area']
            padding = 0.2
            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']
            x_pad, y_pad = int(w * padding), int(h * padding)
            x1 = max(0, x - x_pad)
            y1 = max(0, y - y_pad)
            x2 = min(img_width, x + w + x_pad)
            y2 = min(img_height, y + h + y_pad)
            
            face_crop = img[y1:y2, x1:x2]
            
            # --- LOGIC CH·ªåN ·∫¢NH T·ªêT NH·∫§T (SMART AVATAR SELECTION) ---
            should_save_image = True
            if os.path.exists(target_path):
                # N·∫øu ·∫£nh ƒë√£ t·ªìn t·∫°i, so s√°nh ch·∫•t l∆∞·ª£ng (D·ª±a tr√™n ƒë·ªô ph√¢n gi·∫£i)
                try:
                    old_img = cv2.imread(target_path)
                    if old_img is not None:
                        old_h, old_w = old_img.shape[:2]
                        new_h, new_w = face_crop.shape[:2]
                        
                        old_area = old_w * old_h
                        new_area = new_w * new_h
                        
                        # Ch·ªâ thay th·∫ø n·∫øu ·∫£nh m·ªõi L·ªöN H∆†N ·∫£nh c≈© (R√µ n√©t h∆°n)
                        if new_area <= old_area:
                            should_save_image = False
                            print(f"‚ÑπÔ∏è Gi·ªØ nguy√™n Avatar c≈© (M·ªõi: {new_w}x{new_h} <= C≈©: {old_w}x{old_h})")
                        else:
                            print(f"üÜô C·∫≠p nh·∫≠t Avatar ch·∫•t l∆∞·ª£ng cao h∆°n ({old_w}x{old_h} -> {new_w}x{new_h})")
                except:
                    pass # L·ªói ƒë·ªçc ·∫£nh c≈© -> C·ª© ghi ƒë√® cho ch·∫Øc

            if should_save_image:
                cv2.imwrite(target_path, face_crop)
                print(f"‚úÖ ƒê√£ l∆∞u Avatar m·ªõi: {target_path}")
            # --------------------------------------------------------

            # 2. Update Qdrant (C∆° ch·∫ø Multi-Vector: Lu√¥n t·∫°o ƒëi·ªÉm m·ªõi)
            embedding = best_face['embedding']
            
            # T·∫°o ID ng·∫´u nhi√™n cho Vector m·ªõi (Kh√¥ng ghi ƒë√® Vector c≈©)
            import uuid
            point_id = str(uuid.uuid4())
            print(f"‚ûï Th√™m d·ªØ li·ªáu h·ªçc m·ªõi cho {mssv} (Point ID: {point_id})...")

            client.upsert(
                collection_name=COLLECTION_NAME,
                points=[
                    PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={"student_id": mssv}
                    )
                ]
            )
            print("‚úÖ ƒê√£ n·∫°p th√™m v√†o Qdrant.")

            # 3. Di chuy·ªÉn ·∫£nh g·ªëc sang processed/MSSV/
            processed_student_dir = os.path.join(PROCESSED_DIR, mssv)
            if not os.path.exists(processed_student_dir):
                os.makedirs(processed_student_dir)
            
            shutil.move(file_path, os.path.join(processed_student_dir, filename))
            
            # X√≥a th∆∞ m·ª•c r·ªóng trong collected_faces n·∫øu c·∫ßn (optional)
            parent_dir = os.path.dirname(file_path)
            if not os.listdir(parent_dir) and parent_dir != COLLECTED_DIR:
                os.rmdir(parent_dir)
                
            count_success += 1

        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω {filename}: {e}")

    print("\n" + "="*50)
    print(f"üéâ Ho√†n t·∫•t! ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {count_success}/{len(files)} ·∫£nh.")

if __name__ == "__main__":
    process_collected_images()
