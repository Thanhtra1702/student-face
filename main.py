import cv2
import os
from deepface import DeepFace
import sqlite3
import pandas as pd
from qdrant_client import QdrantClient
import numpy as np
from PIL import Image, ImageDraw, ImageFont

# 1. Kh·ªüi t·∫°o Qdrant Client v√† Database
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
QDRANT_PATH = os.path.join(BASE_DIR, "qdrant_db")
COLLECTION_NAME = "student_faces"

# Kh·ªüi t·∫°o client
client = QdrantClient(path=QDRANT_PATH)

def get_student_info(student_id):
    conn = sqlite3.connect(os.path.join(BASE_DIR, 'student_info.db'))
    query = f"SELECT name, schedule, room FROM students WHERE id = '{student_id}'"
    df = pd.read_sql_query(query, conn)
    conn.close()
    return df

def put_vietnamese_text(img, text, position, font_size=32, color=(0, 255, 0)):
    """V·∫Ω text ti·∫øng Vi·ªát l√™n frame s·ª≠ d·ª•ng PIL"""
    # Chuy·ªÉn t·ª´ BGR (OpenCV) sang RGB (PIL)
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    # S·ª≠ d·ª•ng font m·∫∑c ƒë·ªãnh c·ªßa Windows h·ªó tr·ª£ ti·∫øng Vi·ªát
    try:
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        font = ImageFont.load_default()
    
    # V·∫Ω text
    draw.text(position, text, font=font, fill=color)
    
    # Chuy·ªÉn l·∫°i sang BGR (OpenCV)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

def get_largest_face(faces_data):
    """Ch·ªçn khu√¥n m·∫∑t l·ªõn nh·∫•t (g·∫ßn camera nh·∫•t) t·ª´ danh s√°ch khu√¥n m·∫∑t"""
    if not faces_data:
        return None
    
    largest_face = None
    max_area = 0
    
    for face in faces_data:
        if 'facial_area' in face:
            area = face['facial_area']
            face_area = area['w'] * area['h']
            if face_area > max_area:
                max_area = face_area
                largest_face = face
    
    return largest_face if largest_face else faces_data[0]

def is_face_in_frame(face_area, frame_center, frame_size, scale=2):
    """Ki·ªÉm tra xem khu√¥n m·∫∑t c√≥ n·∫±m trong khung oval kh√¥ng"""
    # Scale l·∫°i t·ªça ƒë·ªô v√¨ ƒë√£ resize
    face_x = face_area['x'] * scale
    face_y = face_area['y'] * scale
    face_w = face_area['w'] * scale
    face_h = face_area['h'] * scale
    
    # T√≠nh t√¢m khu√¥n m·∫∑t
    face_center_x = face_x + face_w // 2
    face_center_y = face_y + face_h // 2
    
    # T√≠nh kho·∫£ng c√°ch t·ª´ t√¢m khu√¥n m·∫∑t ƒë·∫øn t√¢m khung
    dx = abs(face_center_x - frame_center[0])
    dy = abs(face_center_y - frame_center[1])
    
    # Ki·ªÉm tra xem t√¢m khu√¥n m·∫∑t c√≥ n·∫±m trong ellipse kh√¥ng
    # C√¥ng th·ª©c ellipse: (x/a)^2 + (y/b)^2 <= 1
    a = frame_size[0] // 2  # B√°n tr·ª•c ngang
    b = frame_size[1] // 2  # B√°n tr·ª•c d·ªçc
    
    return (dx / a) ** 2 + (dy / b) ** 2 <= 1

def draw_face_guide_frame(frame, progress=0):
    """V·∫Ω khung h∆∞·ªõng d·∫´n h√¨nh oval ·ªü gi·ªØa m√†n h√¨nh v·ªõi progress bar"""
    h, w = frame.shape[:2]
    
    # K√≠ch th∆∞·ªõc khung oval (tƒÉng l√™n 50% chi·ªÅu r·ªông v√† 70% chi·ªÅu cao)
    oval_w = int(w * 0.5)
    oval_h = int(h * 0.7)
    
    # T√¢m khung
    center_x = w // 2
    center_y = h // 2
    
    if progress > 0:
        # V·∫Ω progress bar (arc m√†u xanh ch·∫°y quanh oval)
        # progress t·ª´ 0 ƒë·∫øn 100
        angle = int(360 * progress / 100)
        cv2.ellipse(frame, (center_x, center_y), (oval_w // 2, oval_h // 2), 
                    0, -90, -90 + angle, (0, 255, 0), 8)  # M√†u xanh, ƒë·ªô d√†y 8
        
        # V·∫Ω ph·∫ßn c√≤n l·∫°i m√†u tr·∫Øng m·ªù
        if angle < 360:
            cv2.ellipse(frame, (center_x, center_y), (oval_w // 2, oval_h // 2), 
                        0, -90 + angle, 270, (255, 255, 255), 3)
    else:
        # V·∫Ω ellipse tr·∫Øng b√¨nh th∆∞·ªùng khi ch∆∞a c√≥ progress
        cv2.ellipse(frame, (center_x, center_y), (oval_w // 2, oval_h // 2), 
                    0, 0, 360, (255, 255, 255), 3)
    
    # V·∫Ω text h∆∞·ªõng d·∫´n
    if progress == 0:
        frame = put_vietnamese_text(frame, "ƒê·∫∑t khu√¥n m·∫∑t v√†o khung", 
                                    (center_x - 150, center_y - oval_h // 2 - 50), 
                                    font_size=24, color=(255, 255, 255))
    elif progress < 100:
        frame = put_vietnamese_text(frame, "ƒêang qu√©t...", 
                                    (center_x - 80, center_y - oval_h // 2 - 50), 
                                    font_size=28, color=(0, 255, 0))
    
    return frame, (center_x, center_y), (oval_w, oval_h)

def draw_student_info(frame, name, student_id):
    """V·∫Ω th√¥ng tin sinh vi√™n ·ªü g√≥c tr√™n b√™n tr√°i (nh·ªè g·ªçn)"""
    # V·∫Ω background semi-transparent cho text (nh·ªè h∆°n)
    overlay = frame.copy()
    cv2.rectangle(overlay, (10, 10), (320, 90), (0, 0, 0), -1)
    cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
    
    # V·∫Ω th√¥ng tin v·ªõi font nh·ªè h∆°n
    frame = put_vietnamese_text(frame, f"MSSV: {student_id}", 
                                (20, 25), font_size=18, color=(0, 255, 0))
    frame = put_vietnamese_text(frame, f"{name}", 
                                (20, 55), font_size=22, color=(255, 255, 255))
    
    return frame

# 2. Kh·ªüi t·∫°o Camera
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Gi·∫£m resolution ƒë·ªÉ tƒÉng t·ªëc
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

print("H·ªá th·ªëng Kiosk FPT ƒëang s·∫µn s√†ng. ƒêang qu√©t khu√¥n m·∫∑t...")
print("ƒê·∫∑t khu√¥n m·∫∑t v√†o khung oval ƒë·ªÉ t·ª± ƒë·ªông nh·∫≠n di·ªán | Nh·∫•n 'q' ƒë·ªÉ tho√°t")

frame_count = 0
display_frame = None
last_scan_time = 0
scan_cooldown = 2  # Th·ªùi gian ch·ªù gi·ªØa c√°c l·∫ßn scan (gi√¢y) - gi·∫£m xu·ªëng 2s
face_detected_time = None  # Th·ªùi ƒëi·ªÉm ph√°t hi·ªán khu√¥n m·∫∑t
countdown_duration = 3  # 3 gi√¢y countdown
is_recognizing = False  # ƒêang trong qu√° tr√¨nh nh·∫≠n di·ªán
recognition_result = None  # L∆∞u k·∫øt qu·∫£ nh·∫≠n di·ªán
recognition_started = False  # ƒê√£ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán ch∆∞a

import time
import threading

def check_face_quality(frame, face_area):
    """Ki·ªÉm tra ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t"""
    try:
        x, y, w, h = face_area['x'], face_area['y'], face_area['w'], face_area['h']
        
        # Crop khu√¥n m·∫∑t
        face_crop = frame[y:y+h, x:x+w]
        
        if face_crop.size == 0:
            return False, "Khu√¥n m·∫∑t qu√° nh·ªè"
        
        # 1. Ki·ªÉm tra k√≠ch th∆∞·ªõc (ph·∫£i ƒë·ªß l·ªõn)
        if w < 80 or h < 80:
            return False, "Khu√¥n m·∫∑t qu√° nh·ªè"
        
        # 2. Ki·ªÉm tra ƒë·ªô s√°ng
        gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)
        brightness = np.mean(gray)
        if brightness < 40 or brightness > 220:
            return False, "√Ånh s√°ng kh√¥ng ph√π h·ª£p"
        
        # 3. Ki·ªÉm tra ƒë·ªô n√©t (blur detection)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        if laplacian_var < 100:
            return False, "·∫¢nh b·ªã m·ªù"
        
        return True, "OK"
    except:
        return False, "L·ªói ki·ªÉm tra ch·∫•t l∆∞·ª£ng"

def recognize_face_async(small_frame, frame_center, frame_size):
    """Nh·∫≠n di·ªán khu√¥n m·∫∑t v·ªõi multi-frame averaging v√† re-ranking th√¥ng minh"""
    global recognition_result, is_recognizing
    
    try:
        # Multi-frame averaging: L·∫•y 3 embeddings t·ª´ c√°c frame kh√°c nhau
        embeddings_list = []
        
        for attempt in range(3):
            # Preprocessing CLAHE
            lab = cv2.cvtColor(small_frame, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            cl = clahe.apply(l)
            limg = cv2.merge((cl,a,b))
            frame_enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
            
            # Th√™m m·ªôt ch√∫t nhi·ªÖu ng·∫´u nhi√™n ƒë·ªÉ t·∫°o s·ª± ƒëa d·∫°ng gi·ªØa c√°c frame
            if attempt > 0:
                noise = np.random.normal(0, 2, frame_enhanced.shape).astype(np.uint8)
                frame_enhanced = cv2.add(frame_enhanced, noise)
            
            # Detector Mediapipe
            try:
                results = DeepFace.represent(
                    img_path=frame_enhanced, 
                    model_name="ArcFace",
                    enforce_detection=True,
                    detector_backend="mediapipe",
                    align=True
                )
            except:
                try:
                    results = DeepFace.represent(
                        img_path=small_frame, 
                        model_name="ArcFace",
                        enforce_detection=True,
                        detector_backend="opencv",
                        align=True
                    )
                except:
                    results = None
            
            if results:
                faces_in_frame = []
                for face in results:
                    if 'facial_area' in face:
                        if is_face_in_frame(face['facial_area'], frame_center, frame_size, scale=1.0):
                            quality_ok, quality_msg = check_face_quality(small_frame, face['facial_area'])
                            if quality_ok:
                                faces_in_frame.append(face)
                
                if faces_in_frame:
                    selected_face = get_largest_face(faces_in_frame) if len(faces_in_frame) > 1 else faces_in_frame[0]
                    embeddings_list.append(selected_face["embedding"])
        
        # N·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c embedding n√†o
        if len(embeddings_list) == 0:
            recognition_result = {
                'success': False,
                'message': "Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t ho·∫∑c ch·∫•t l∆∞·ª£ng kh√¥ng ƒë·ªß."
            }
            is_recognizing = False
            return
        
        # T√≠nh embedding trung b√¨nh
        avg_embedding = np.mean(embeddings_list, axis=0).tolist()
        
        # T√¨m ki·∫øm v·ªõi embedding trung b√¨nh
        search_result = client.query_points(
            collection_name=COLLECTION_NAME,
            query=avg_embedding,
            limit=5  # L·∫•y top 5 ƒë·ªÉ re-ranking
        ).points
        
        if search_result and len(search_result) > 0:
            best_match = search_result[0]
            
            # Re-ranking v·ªõi Confidence Ratio
            confidence_gap = 0
            confidence_ratio = 1.0
            
            if len(search_result) > 1:
                confidence_gap = best_match.score - search_result[1].score
                # Tr√°nh chia cho 0
                if search_result[1].score > 0:
                    confidence_ratio = best_match.score / search_result[1].score
            
            # Logic nh·∫≠n di·ªán n√¢ng cao v·ªõi Confidence Ratio
            accept = False
            
            # Tier 1: Score r·∫•t cao (>0.60) - Ch·∫•p nh·∫≠n ngay
            if best_match.score > 0.60:
                accept = True
            # Tier 2: Score cao (0.50-0.60) - C·∫ßn ratio > 1.05 HO·∫∂C gap > 0.04
            elif best_match.score > 0.50:
                if confidence_ratio > 1.05 or confidence_gap > 0.04:
                    accept = True
            # Tier 3: Score trung b√¨nh (0.40-0.50) - C·∫ßn ratio > 1.10 V√Ä gap > 0.06
            elif best_match.score > 0.40:
                if confidence_ratio > 1.10 and confidence_gap > 0.06:
                    accept = True
            # Tier 4: Score th·∫•p (0.35-0.40) - C·∫ßn ratio > 1.15 V√Ä gap > 0.10
            elif best_match.score > 0.35:
                if confidence_ratio > 1.15 and confidence_gap > 0.10:
                    accept = True
            
            if accept:
                student_id = best_match.payload["student_id"]
                score = best_match.score
                info = get_student_info(student_id)
                
                if not info.empty:
                    recognition_result = {
                        'success': True,
                        'student_id': student_id,
                        'score': score,
                        'name': info.iloc[0]['name'],
                        'schedule': info.iloc[0]['schedule'],
                        'room': info.iloc[0]['room']
                    }
                else:
                    recognition_result = {
                        'success': False,
                        'message': f"Nh·∫≠n di·ªán ƒë∆∞·ª£c {student_id} nh∆∞ng ch∆∞a c√≥ d·ªØ li·ªáu l√Ω l·ªãch."
                    }
            else:
                if best_match.score < 0.35:
                    recognition_result = {
                        'success': False,
                        'message': f"ƒê·ªô tin c·∫≠y qu√° th·∫•p ({best_match.score:.2f})."
                    }
                else:
                    recognition_result = {
                        'success': False,
                        'message': f"Kh√¥ng th·ªÉ x√°c ƒë·ªãnh (Score: {best_match.score:.2f}, Gap: {confidence_gap:.2f}, Ratio: {confidence_ratio:.2f})."
                    }
        else:
            recognition_result = {
                'success': False,
                'message': "Kh√¥ng t√¨m th·∫•y th√¥ng tin sinh vi√™n ph√π h·ª£p."
            }
    
    except Exception as e:
        recognition_result = {'success': False, 'message': f"L·ªói: {str(e)}"}
    
    is_recognizing = False

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    frame_count += 1
    current_time = time.time()
    
    frame = cv2.flip(frame, 1)
    # T·∫°o b·∫£n sao ƒë·ªÉ v·∫Ω
    display_frame = frame.copy()
    
    # Ki·ªÉm tra cooldown
    if current_time - last_scan_time < scan_cooldown:
        # ƒêang trong th·ªùi gian ch·ªù, ch·ªâ hi·ªÉn th·ªã khung
        display_frame, frame_center, frame_size = draw_face_guide_frame(display_frame)
        cv2.imshow("Kiosk Tra Cuu Lich Hoc FPT", display_frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        continue
    
    # N·∫øu ƒëang trong qu√° tr√¨nh countdown
    if face_detected_time is not None:
        elapsed = current_time - face_detected_time
        remaining = countdown_duration - elapsed
        
        # B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán ngay khi countdown b·∫Øt ƒë·∫ßu (ch·ªâ 1 l·∫ßn)
        if not recognition_started and not is_recognizing:
            recognition_started = True
            is_recognizing = True
            recognition_result = None
            
            # Nh·∫≠n di·ªán v·ªõi ·∫£nh full resolution ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
            # Kh√¥ng resize, d√πng ·∫£nh g·ªëc 640x480
            display_frame, frame_center, frame_size = draw_face_guide_frame(display_frame)
            
            thread = threading.Thread(target=recognize_face_async, 
                                     args=(frame, frame_center, frame_size))
            thread.daemon = True
            thread.start()
        
        if remaining > 0:
            # V·∫Ω countdown v√† progress bar m∆∞·ª£t m√†
            progress = int((elapsed / countdown_duration) * 100)
            display_frame, frame_center, frame_size = draw_face_guide_frame(display_frame, progress)
            
            # Hi·ªÉn th·ªã s·ªë ƒë·∫øm ng∆∞·ª£c
            countdown_text = f"{int(remaining) + 1}"
            h, w = display_frame.shape[:2]
            display_frame = put_vietnamese_text(display_frame, countdown_text,
                                                (w//2 - 20, h//2), 
                                                font_size=60, color=(0, 255, 0))
            cv2.imshow("Kiosk Tra Cuu Lich Hoc FPT", display_frame)
        else:
            # H·∫øt countdown - Hi·ªÉn th·ªã k·∫øt qu·∫£
            if recognition_result is not None:
                if recognition_result['success']:
                    print(f"\n‚úÖ Nh·∫≠n di·ªán ƒë∆∞·ª£c MSSV: {recognition_result['student_id']} (ƒê·ªô tin c·∫≠y: {recognition_result['score']:.2f})")
                    print(f"--- CH√ÄO M·ª™NG SINH VI√äN ---")
                    print(f"H·ªç t√™n: {recognition_result['name']}")
                    print(f"L·ªãch h·ªçc h√¥m nay:")
                    print(f"üìå M√¥n: {recognition_result['schedule']}, Ph√≤ng: {recognition_result['room']}")
                    print("----------------------------")
                    
                    # Hi·ªÉn th·ªã th√¥ng tin
                    result_frame = frame.copy()
                    result_frame, _, _ = draw_face_guide_frame(result_frame, 100)
                    result_frame = draw_student_info(result_frame, 
                                                    recognition_result['name'], 
                                                    recognition_result['student_id'])
                    cv2.imshow("Kiosk Tra Cuu Lich Hoc FPT", result_frame)
                    cv2.waitKey(3000)  # Hi·ªÉn th·ªã 3 gi√¢y
                    
                    last_scan_time = time.time()
                else:
                    print(f"‚ö†Ô∏è {recognition_result['message']}")
                    last_scan_time = time.time()
            else:
                # Ch∆∞a c√≥ k·∫øt qu·∫£, ch·ªù th√™m
                if not is_recognizing:
                    print("‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ nh·∫≠n di·ªán.")
                    last_scan_time = time.time()
            
            # Reset tr·∫°ng th√°i
            face_detected_time = None
            recognition_started = False
            recognition_result = None
    
    # Ki·ªÉm tra khu√¥n m·∫∑t m·ªói 15 frames (gi·∫£m t·∫ßn su·∫•t ƒë·ªÉ tƒÉng hi·ªáu su·∫•t)
    elif frame_count % 15 == 0 and not is_recognizing:
        try:
            # Resize frame ƒë·ªÉ tƒÉng t·ªëc
            small_frame = cv2.resize(frame, (320, 240))
            
            # Ph√°t hi·ªán khu√¥n m·∫∑t
            results = DeepFace.represent(
                img_path=small_frame, 
                model_name="Facenet512", 
                enforce_detection=True,
                detector_backend="opencv"
            )

            if results:
                # L·ªçc khu√¥n m·∫∑t trong khung oval
                display_frame, frame_center, frame_size = draw_face_guide_frame(display_frame)
                
                faces_in_frame = []
                for face in results:
                    if 'facial_area' in face:
                        if is_face_in_frame(face['facial_area'], frame_center, frame_size):
                            faces_in_frame.append(face)
                
                if faces_in_frame and face_detected_time is None:
                    # L·∫ßn ƒë·∫ßu ph√°t hi·ªán khu√¥n m·∫∑t trong khung
                    face_detected_time = current_time
                    print("\n‚úì Ph√°t hi·ªán khu√¥n m·∫∑t trong khung! ƒêang ƒë·∫øm ng∆∞·ª£c...")
                elif not faces_in_frame and face_detected_time is not None:
                    # Khu√¥n m·∫∑t r·ªùi kh·ªèi khung trong qu√° tr√¨nh countdown
                    print("‚ö†Ô∏è Khu√¥n m·∫∑t r·ªùi kh·ªèi khung. H·ªßy countdown.")
                    face_detected_time = None
                    display_frame, _, _ = draw_face_guide_frame(display_frame)
                elif not faces_in_frame:
                    # Kh√¥ng c√≥ khu√¥n m·∫∑t trong khung
                    face_detected_time = None
                    display_frame, _, _ = draw_face_guide_frame(display_frame)
            else:
                # Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t
                if face_detected_time is not None:
                    print("‚ö†Ô∏è Khu√¥n m·∫∑t r·ªùi kh·ªèi khung. H·ªßy countdown.")
                face_detected_time = None
                display_frame, _, _ = draw_face_guide_frame(display_frame)

        except ValueError as e:
            if "Face could not be detected" in str(e):
                if face_detected_time is not None:
                    print("‚ö†Ô∏è Khu√¥n m·∫∑t r·ªùi kh·ªèi khung. H·ªßy countdown.")
                face_detected_time = None
                display_frame, _, _ = draw_face_guide_frame(display_frame)
        except Exception as e:
            print(f"‚ùå L·ªói h·ªá th·ªëng: {e}")
    else:
        # Frame b√¨nh th∆∞·ªùng, ch·ªâ v·∫Ω khung
        if face_detected_time is None and not is_recognizing:
            display_frame, _, _ = draw_face_guide_frame(display_frame)

    # Hi·ªÉn th·ªã frame (n·∫øu ch∆∞a ƒë∆∞·ª£c hi·ªÉn th·ªã trong countdown)
    if face_detected_time is None or is_recognizing:
        cv2.imshow("Kiosk Tra Cuu Lich Hoc FPT", display_frame)
    
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
client.close()
print("üëã ƒê√£ ƒë√≥ng h·ªá th·ªëng Kiosk.")
